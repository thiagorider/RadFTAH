       Este trabalho visa revisar e avaliar diversas técnicas de detecção de erros em software, com o objetivo de proteger processadores contra falhas transientes e sua viabilidade para implementação em hardware de forma a atuar dinamicamente selecionando qual a melhor técnica, levando em consideração a melhor relação entre o custo e a taxa de detecção de erros. Tem relevância no contexto de uso de sistemas micro processados em ambientes hostis cuja exposição à radiação ou ainda, influência eletromagnética podem causar efeitos inesperados no comportamento do circuito.
       O problema de um circuito ser mais sensível à estes fatores está ligado diretamente ao poder de integração de circuito cada vez maior, que ocasiona a diminuição de seus componentes mais básicos, os transistores. Com chaves cada vez menores, a chance de uma partícula afetar um ou mais destes elementos é muito maior. Outro fator tão importante quanto o anterior é o fato das frequências de operação a que estes circuitos são submetidos ser cada vez maior, o que significa que o intervalo entre as bordas de relógio são mais curtos, aumentando a chance de um pulso espúrio ser capturado pela lógica.
       O uso de técnicas de detecção de erros permite a construção de um sistema tolerante à falhas, bastando se definir uma rotina para quando se detecta um erro, e para cada técnica existe um custo intrínseco em termos de área, potência, desempenho, tempo de execução e taxa de detecção de erros. A possibilidade de um hardware que permita variar as técnicas tem forte apelo tecnológico por tentar minimizar os custos envolvidos a cada variação das condições a qual o circuito está submetido.
       Assim, este trabalho apresenta as diversas técnicas já propostas em diversas publicações e analisa a viabilidade de sua implementação em hardware e seu grau de complexidade, propondo um roadmap para implementação das mesmas em um sistema dinâmico.
